{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Retrieval Module Verification\n",
    "\n",
    "This notebook tests the `src.retrieval` module which handles:\n",
    "- **Dense Vector Search** using Qdrant + BGE embeddings\n",
    "- **Cross-Encoder Reranking** for high precision (top 20 â†’ top 5)\n",
    "- **Parent Content Extraction** via `format_docs_for_gen()`\n",
    "\n",
    "Uses a **small subset (50 docs)** for fast testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "QDRANT_PATH = os.path.join(PROJECT_ROOT, \"qdrant_test_db\")\n",
    "MAX_DOCS = 50\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Test subset size: {MAX_DOCS} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-section",
   "metadata": {},
   "source": [
    "## Step 0: Prepare Test Collection\n",
    "\n",
    "Create a small Qdrant collection for testing retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract corpus if needed\n",
    "corpus_dir = os.path.join(PROJECT_ROOT, \"dataset/corpora/passage_level\")\n",
    "jsonl_file = os.path.join(corpus_dir, \"govt.jsonl\")\n",
    "zip_file = os.path.join(corpus_dir, \"govt.jsonl.zip\")\n",
    "\n",
    "if not os.path.exists(jsonl_file) and os.path.exists(zip_file):\n",
    "    print(\"Extracting corpus...\")\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zf:\n",
    "        zf.extractall(corpus_dir)\n",
    "    print(\"Corpus extracted\")\n",
    "else:\n",
    "    print(f\"Corpus ready: govt.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "# Check if collection exists\n",
    "need_create = True\n",
    "if os.path.exists(QDRANT_PATH):\n",
    "    try:\n",
    "        client = QdrantClient(path=QDRANT_PATH)\n",
    "        info = client.get_collection(\"mtrag_test\")\n",
    "        print(f\"Test collection exists: {info.points_count} points\")\n",
    "        client.close()\n",
    "        need_create = False\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if need_create:\n",
    "    print(\"Creating test collection...\")\n",
    "    \n",
    "    # Load subset\n",
    "    docs = []\n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= MAX_DOCS:\n",
    "                break\n",
    "            item = json.loads(line)\n",
    "            text = item.get(\"text\", \"\").strip()\n",
    "            if text:\n",
    "                docs.append(Document(page_content=text, metadata={\"doc_id\": item.get(\"id\", str(i))}))\n",
    "    print(f\"   â€¢ Loaded {len(docs)} documents\")\n",
    "    \n",
    "    # Chunk\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    print(f\"   â€¢ Split into {len(chunks)} chunks\")\n",
    "    \n",
    "    # Build embeddings (using small model for speed)\n",
    "    print(\"   â€¢ Building embeddings (bge-small-en)...\")\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "        model_kwargs={\"device\": \"cpu\"}\n",
    "    )\n",
    "    \n",
    "    # Create collection\n",
    "    client = QdrantClient(path=QDRANT_PATH)\n",
    "    if client.collection_exists(\"mtrag_test\"):\n",
    "        client.delete_collection(\"mtrag_test\")\n",
    "    client.create_collection(\n",
    "        collection_name=\"mtrag_test\",\n",
    "        vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    "    )\n",
    "    \n",
    "    vectorstore = QdrantVectorStore(client=client, collection_name=\"mtrag_test\", embedding=embedding_model)\n",
    "    vectorstore.add_documents(chunks)\n",
    "    print(f\"\\nTest collection created with {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retriever-section",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Retriever\n",
    "\n",
    "Create a retriever from the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-retriever",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize for clean state\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "client = QdrantClient(path=QDRANT_PATH)\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=client, \n",
    "    collection_name=\"mtrag_test\", \n",
    "    embedding=embedding_model\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(f\"Retriever Configuration:\")\n",
    "print(f\"   â€¢ Type: {type(retriever).__name__}\")\n",
    "print(f\"   â€¢ Top-K: 5 documents\")\n",
    "print(f\"   â€¢ Embedding model: bge-small-en-v1.5\")\n",
    "\n",
    "print(\"\\nRetriever initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieval-section",
   "metadata": {},
   "source": [
    "## Step 2: Test Retrieval\n",
    "\n",
    "Query the retriever and examine results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"government regulations\"\n",
    "print(f\"Query: '{query}'\")\n",
    "\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"\\nRetrieved {len(docs)} documents:\")\n",
    "for i, doc in enumerate(docs[:3]):\n",
    "    print(f\"\\n   Document {i+1}:\")\n",
    "    print(f\"   â€¢ Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"   â€¢ Doc ID: {doc.metadata.get('doc_id', 'N/A')}\")\n",
    "\n",
    "print(\"\\nRetrieval working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "format-section",
   "metadata": {},
   "source": [
    "## Step 3: Test `format_docs_for_gen()`\n",
    "\n",
    "This function from `src.retrieval`:\n",
    "1. Extracts parent content from retrieved documents\n",
    "2. Deduplicates to avoid repetition\n",
    "3. Concatenates into context string for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retrieval import format_docs_for_gen\n",
    "\n",
    "context = format_docs_for_gen(docs)\n",
    "\n",
    "print(f\"Context Statistics:\")\n",
    "print(f\"   â€¢ Total length: {len(context)} characters\")\n",
    "print(f\"   â€¢ Unique documents: {len(docs)}\")\n",
    "\n",
    "print(f\"\\nðŸ“„ Context Preview (first 300 chars):\")\n",
    "print(f\"   {context[:300]}...\")\n",
    "\n",
    "print(\"\\nformat_docs_for_gen() working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-section",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Remove test files after verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Close client first\n",
    "client.close()\n",
    "\n",
    "# Remove test database\n",
    "if os.path.exists(QDRANT_PATH):\n",
    "    shutil.rmtree(QDRANT_PATH)\n",
    "    print(f\"Removed test database: {QDRANT_PATH}\")\n",
    "\n",
    "print(\"\\nAll retrieval tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}