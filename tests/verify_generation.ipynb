{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Generation Module Verification\n",
    "\n",
    "This notebook tests the `src.generation` module which provides:\n",
    "- **Query Rewriter** - Converts context-dependent questions to standalone form\n",
    "- **Generator** - Produces answers with I_DONT_KNOW fallback\n",
    "- **Retrieval Grader** - CRAG component for document relevance\n",
    "- **Hallucination Grader** - Self-RAG component for answer grounding\n",
    "\n",
    "**Note:** Full tests require GPU (Llama 3.1 8B). Run on Kaggle for complete testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.generation import (\n",
    "    create_generation_components,\n",
    "    GenerationComponents,\n",
    "    GradeDocuments,\n",
    "    GradeHallucinations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pydantic-section",
   "metadata": {},
   "source": [
    "## Step 1: Verify Pydantic Models\n",
    "\n",
    "These define the JSON output schemas for graders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-pydantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pydantic Models:\")\n",
    "print(f\"   • GradeDocuments: {list(GradeDocuments.model_fields.keys())}\")\n",
    "print(f\"   • GradeHallucinations: {list(GradeHallucinations.model_fields.keys())}\")\n",
    "\n",
    "# Test instantiation\n",
    "doc_grade = GradeDocuments(binary_score=\"yes\")\n",
    "hal_grade = GradeHallucinations(binary_score=\"no\")\n",
    "\n",
    "print(f\"\\n   Example GradeDocuments: {doc_grade.model_dump()}\")\n",
    "print(f\"   Example GradeHallucinations: {hal_grade.model_dump()}\")\n",
    "\n",
    "print(\"\\nPydantic models work!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataclass-section",
   "metadata": {},
   "source": [
    "## Step 2: Verify GenerationComponents Dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-dataclass",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "print(\"GenerationComponents:\")\n",
    "if dataclasses.is_dataclass(GenerationComponents):\n",
    "    fields = [f.name for f in dataclasses.fields(GenerationComponents)]\n",
    "    print(f\"   • Type: dataclass\")\n",
    "    print(f\"   • Fields: {fields}\")\n",
    "else:\n",
    "    print(f\"   • Type: {type(GenerationComponents).__name__}\")\n",
    "\n",
    "print(\"\\nGenerationComponents structure verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "factory-section",
   "metadata": {},
   "source": [
    "## Step 3: Test Factory Function (GPU Required)\n",
    "\n",
    "Load Llama model and create components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use smaller model for faster testing\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "print(f\"Loading {MODEL_ID}...\")\n",
    "components = create_generation_components(model_id=MODEL_ID)\n",
    "\n",
    "print(f\"\\nComponents Created:\")\n",
    "print(f\"   • llm: {type(components.llm).__name__}\")\n",
    "print(f\"   • query_rewriter: {type(components.query_rewriter).__name__}\")\n",
    "print(f\"   • generator: {type(components.generator).__name__}\")\n",
    "print(f\"   • retrieval_grader: {type(components.retrieval_grader).__name__}\")\n",
    "print(f\"   • hallucination_grader: {type(components.hallucination_grader).__name__}\")\n",
    "\n",
    "print(\"\\nAll components initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chains-section",
   "metadata": {},
   "source": [
    "## Step 4: Test Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-rewriter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query Rewriter\n",
    "print(\"Testing Query Rewriter...\")\n",
    "\n",
    "# NOTE: query_rewriter expects 'messages' key (not 'chat_history')\n",
    "result = components.query_rewriter.invoke({\n",
    "    \"messages\": [(\"user\", \"Who is the CEO of Apple?\"), (\"assistant\", \"Tim Cook.\")],\n",
    "    \"question\": \"How old is he?\"\n",
    "})\n",
    "\n",
    "print(f\"   Input: 'How old is he?' (with context about Tim Cook)\")\n",
    "print(f\"   Output: '{result}'\")\n",
    "print(\"Query Rewriter works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Generator\n",
    "print(\"Testing Generator...\")\n",
    "\n",
    "result = components.generator.invoke({\n",
    "    \"context\": \"Tim Cook is the CEO of Apple. He was born on November 1, 1960.\",\n",
    "    \"question\": \"Who is Tim Cook?\"\n",
    "})\n",
    "\n",
    "print(f\"   Question: 'Who is Tim Cook?'\")\n",
    "print(f\"   Answer: '{result[:200]}'\")\n",
    "print(\"Generator works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-graders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Retrieval Grader\n",
    "print(\"Testing Retrieval Grader...\")\n",
    "\n",
    "result = components.retrieval_grader.invoke({\n",
    "    \"document\": \"Tim Cook is the CEO of Apple since 2011.\",\n",
    "    \"question\": \"Who is the CEO of Apple?\"\n",
    "})\n",
    "\n",
    "print(f\"   Document relevant? {result}\")\n",
    "print(\"Retrieval Grader works!\")\n",
    "\n",
    "# Test Hallucination Grader\n",
    "print(\"\\nTesting Hallucination Grader...\")\n",
    "\n",
    "result = components.hallucination_grader.invoke({\n",
    "    \"documents\": \"Tim Cook was born on November 1, 1960.\",\n",
    "    \"generation\": \"Tim Cook is currently 64 years old.\"\n",
    "})\n",
    "\n",
    "print(f\"   Answer supported? {result}\")\n",
    "print(\"Hallucination Grader works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Components verified:**\n",
    "- Pydantic models (GradeDocuments, GradeHallucinations)\n",
    "- GenerationComponents dataclass\n",
    "- Query Rewriter chain\n",
    "- Generator chain\n",
    "- Retrieval Grader chain\n",
    "- Hallucination Grader chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
