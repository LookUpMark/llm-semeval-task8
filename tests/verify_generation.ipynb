{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Generation Module Verification\n",
                "\n",
                "This notebook tests the `src.generation` module which provides:\n",
                "- **Query Rewriter** - Converts context-dependent questions to standalone form\n",
                "- **Generator** - Produces answers with I_DONT_KNOW fallback\n",
                "- **Retrieval Grader** - CRAG component for document relevance\n",
                "- **Hallucination Grader** - Self-RAG component for answer grounding\n",
                "\n",
                "**Note:** Full tests require GPU (Llama 3.1 8B). Run on Kaggle for complete testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marcantoniolopez/Documenti/github/projects/llm-semeval-task8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "sys.path.append(os.path.abspath(\"..\"))\n",
                "\n",
                "from src.generation import (\n",
                "    create_generation_components,\n",
                "    GenerationComponents,\n",
                "    GradeDocuments,\n",
                "    GradeHallucinations\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pydantic-section",
            "metadata": {},
            "source": [
                "## Step 1: Verify Pydantic Models\n",
                "\n",
                "These define the JSON output schemas for graders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "test-pydantic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“Š Pydantic Models:\n",
                        "   â€¢ GradeDocuments: ['binary_score']\n",
                        "   â€¢ GradeHallucinations: ['binary_score']\n",
                        "\n",
                        "   Example GradeDocuments: {'binary_score': 'yes'}\n",
                        "   Example GradeHallucinations: {'binary_score': 'no'}\n",
                        "\n",
                        "âœ… Pydantic models work!\n"
                    ]
                }
            ],
            "source": [
                "print(\"ðŸ“Š Pydantic Models:\")\n",
                "print(f\"   â€¢ GradeDocuments: {list(GradeDocuments.model_fields.keys())}\")\n",
                "print(f\"   â€¢ GradeHallucinations: {list(GradeHallucinations.model_fields.keys())}\")\n",
                "\n",
                "# Test instantiation\n",
                "doc_grade = GradeDocuments(binary_score=\"yes\")\n",
                "hal_grade = GradeHallucinations(binary_score=\"no\")\n",
                "\n",
                "print(f\"\\n   Example GradeDocuments: {doc_grade.model_dump()}\")\n",
                "print(f\"   Example GradeHallucinations: {hal_grade.model_dump()}\")\n",
                "\n",
                "print(\"\\nâœ… Pydantic models work!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dataclass-section",
            "metadata": {},
            "source": [
                "## Step 2: Verify GenerationComponents Dataclass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "test-dataclass",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“Š GenerationComponents:\n",
                        "   â€¢ Type: dataclass\n",
                        "   â€¢ Fields: ['llm', 'query_rewriter', 'generator', 'retrieval_grader', 'hallucination_grader']\n",
                        "\n",
                        "âœ… GenerationComponents structure verified!\n"
                    ]
                }
            ],
            "source": [
                "import dataclasses\n",
                "\n",
                "print(\"ðŸ“Š GenerationComponents:\")\n",
                "if dataclasses.is_dataclass(GenerationComponents):\n",
                "    fields = [f.name for f in dataclasses.fields(GenerationComponents)]\n",
                "    print(f\"   â€¢ Type: dataclass\")\n",
                "    print(f\"   â€¢ Fields: {fields}\")\n",
                "else:\n",
                "    print(f\"   â€¢ Type: {type(GenerationComponents).__name__}\")\n",
                "\n",
                "print(\"\\nâœ… GenerationComponents structure verified!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "factory-section",
            "metadata": {},
            "source": [
                "## Step 3: Test Factory Function (GPU Required)\n",
                "\n",
                "**Uncomment and run on Kaggle with GPU.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "test-factory",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating Generation Components with model: meta-llama/Meta-Llama-3.1-8B-Instruct...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
                    ]
                }
            ],
            "source": [
                "components = create_generation_components()\n",
                "\n",
                "print(f\"\\nðŸ“Š Components Created:\")\n",
                "print(f\"   â€¢ llm: {type(components.llm).__name__}\")\n",
                "print(f\"   â€¢ query_rewriter: {type(components.query_rewriter).__name__}\")\n",
                "print(f\"   â€¢ generator: {type(components.generator).__name__}\")\n",
                "print(f\"   â€¢ retrieval_grader: {type(components.retrieval_grader).__name__}\")\n",
                "print(f\"   â€¢ hallucination_grader: {type(components.hallucination_grader).__name__}\")\n",
                "\n",
                "print(\"\\nâœ… All components initialized!\")\n",
                "\n",
                "print(\"â­ï¸ Skipped (requires GPU). Uncomment on Kaggle.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "chains-section",
            "metadata": {},
            "source": [
                "## Step 4: Test Chains (GPU Required)\n",
                "\n",
                "**Uncomment and run on Kaggle with GPU.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "test-chains",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test Query Rewriter\n",
                "print(\"ðŸ”„ Testing Query Rewriter...\")\n",
                "result = components.query_rewriter.invoke({\n",
                "    \"chat_history\": \"Human: Who is the CEO?\\nAI: Tim Cook.\",\n",
                "    \"question\": \"How old is he?\"\n",
                "})\n",
                "print(f\"   Input: 'How old is he?' (with context)\")\n",
                "print(f\"   Output: {result}\")\n",
                "\n",
                "# Test Generator\n",
                "print(\"\\nðŸ”„ Testing Generator...\")\n",
                "result = components.generator.invoke({\n",
                "    \"context\": \"Tim Cook is the CEO of Apple. He was born in 1960.\",\n",
                "    \"question\": \"How old is Tim Cook?\"\n",
                "})\n",
                "print(f\"   Question: 'How old is Tim Cook?'\")\n",
                "print(f\"   Answer: {result}\")\n",
                "\n",
                "print(\"\\nâœ… All chains work!\")\n",
                "\n",
                "print(\"â­ï¸ Skipped (requires GPU). Uncomment on Kaggle.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary-section",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "**Local verification (without GPU):**\n",
                "- âœ… Imports work\n",
                "- âœ… Pydantic models work\n",
                "- âœ… GenerationComponents structure verified\n",
                "\n",
                "**Requires Kaggle GPU:**\n",
                "- â³ create_generation_components()\n",
                "- â³ Query Rewriter chain\n",
                "- â³ Generator chain\n",
                "- â³ Retrieval Grader chain\n",
                "- â³ Hallucination Grader chain"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
