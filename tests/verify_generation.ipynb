{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Generation Module Verification\n",
                "\n",
                "This notebook tests the `src.generation` module which provides:\n",
                "- **Query Rewriter** - Converts context-dependent questions to standalone form\n",
                "- **Generator** - Produces answers with I_DONT_KNOW fallback\n",
                "- **Retrieval Grader** - CRAG component for document relevance\n",
                "- **Hallucination Grader** - Self-RAG component for answer grounding\n",
                "\n",
                "**Note:** Full tests require GPU (Llama 3.1 8B). Run on Kaggle for complete testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marcantoniolopez/Documenti/github/projects/llm-semeval-task8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "sys.path.append(os.path.abspath(\"..\"))\n",
                "\n",
                "from src.generation import (\n",
                "    create_generation_components,\n",
                "    GenerationComponents,\n",
                "    GradeDocuments,\n",
                "    GradeHallucinations\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pydantic-section",
            "metadata": {},
            "source": [
                "## Step 1: Verify Pydantic Models\n",
                "\n",
                "These define the JSON output schemas for graders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "test-pydantic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“Š Pydantic Models:\n",
                        "   â€¢ GradeDocuments: ['binary_score']\n",
                        "   â€¢ GradeHallucinations: ['binary_score']\n",
                        "\n",
                        "   Example GradeDocuments: {'binary_score': 'yes'}\n",
                        "   Example GradeHallucinations: {'binary_score': 'no'}\n",
                        "\n",
                        "âœ… Pydantic models work!\n"
                    ]
                }
            ],
            "source": [
                "print(\"ðŸ“Š Pydantic Models:\")\n",
                "print(f\"   â€¢ GradeDocuments: {list(GradeDocuments.model_fields.keys())}\")\n",
                "print(f\"   â€¢ GradeHallucinations: {list(GradeHallucinations.model_fields.keys())}\")\n",
                "\n",
                "# Test instantiation\n",
                "doc_grade = GradeDocuments(binary_score=\"yes\")\n",
                "hal_grade = GradeHallucinations(binary_score=\"no\")\n",
                "\n",
                "print(f\"\\n   Example GradeDocuments: {doc_grade.model_dump()}\")\n",
                "print(f\"   Example GradeHallucinations: {hal_grade.model_dump()}\")\n",
                "\n",
                "print(\"\\nâœ… Pydantic models work!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dataclass-section",
            "metadata": {},
            "source": [
                "## Step 2: Verify GenerationComponents Dataclass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "test-dataclass",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“Š GenerationComponents:\n",
                        "   â€¢ Type: dataclass\n",
                        "   â€¢ Fields: ['llm', 'query_rewriter', 'generator', 'retrieval_grader', 'hallucination_grader']\n",
                        "\n",
                        "âœ… GenerationComponents structure verified!\n"
                    ]
                }
            ],
            "source": [
                "import dataclasses\n",
                "\n",
                "print(\"ðŸ“Š GenerationComponents:\")\n",
                "if dataclasses.is_dataclass(GenerationComponents):\n",
                "    fields = [f.name for f in dataclasses.fields(GenerationComponents)]\n",
                "    print(f\"   â€¢ Type: dataclass\")\n",
                "    print(f\"   â€¢ Fields: {fields}\")\n",
                "else:\n",
                "    print(f\"   â€¢ Type: {type(GenerationComponents).__name__}\")\n",
                "\n",
                "print(\"\\nâœ… GenerationComponents structure verified!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "factory-section",
            "metadata": {},
            "source": [
                "## Step 3: Test Factory Function (GPU Required)\n",
                "\n",
                "Load Llama model and create components."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "test-factory",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Loading meta-llama/Llama-3.2-1B-Instruct...\n",
                        "Creating Generation Components with model: meta-llama/Llama-3.2-1B-Instruct...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cuda:0\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generation Components Ready.\n",
                        "\n",
                        "ðŸ“Š Components Created:\n",
                        "   â€¢ llm: HuggingFacePipeline\n",
                        "   â€¢ query_rewriter: RunnableSequence\n",
                        "   â€¢ generator: RunnableSequence\n",
                        "   â€¢ retrieval_grader: RunnableSequence\n",
                        "   â€¢ hallucination_grader: RunnableSequence\n",
                        "\n",
                        "âœ… All components initialized!\n"
                    ]
                }
            ],
            "source": [
                "# Use smaller model for faster testing\n",
                "MODEL_ID = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
                "\n",
                "print(f\"ðŸ”„ Loading {MODEL_ID}...\")\n",
                "components = create_generation_components(model_id=MODEL_ID)\n",
                "\n",
                "print(f\"\\nðŸ“Š Components Created:\")\n",
                "print(f\"   â€¢ llm: {type(components.llm).__name__}\")\n",
                "print(f\"   â€¢ query_rewriter: {type(components.query_rewriter).__name__}\")\n",
                "print(f\"   â€¢ generator: {type(components.generator).__name__}\")\n",
                "print(f\"   â€¢ retrieval_grader: {type(components.retrieval_grader).__name__}\")\n",
                "print(f\"   â€¢ hallucination_grader: {type(components.hallucination_grader).__name__}\")\n",
                "\n",
                "print(\"\\nâœ… All components initialized!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "chains-section",
            "metadata": {},
            "source": [
                "## Step 4: Test Chains"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "test-rewriter",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Testing Query Rewriter...\n",
                        "   Input: 'How old is he?' (with context about Tim Cook)\n",
                        "   Output: '\n",
                        "\n",
                        "Tim Cook'\n",
                        "âœ… Query Rewriter works!\n"
                    ]
                }
            ],
            "source": [
                "# Test Query Rewriter\n",
                "print(\"ðŸ”„ Testing Query Rewriter...\")\n",
                "\n",
                "# NOTE: query_rewriter expects 'messages' key (not 'chat_history')\n",
                "result = components.query_rewriter.invoke({\n",
                "    \"messages\": [(\"user\", \"Who is the CEO of Apple?\"), (\"assistant\", \"Tim Cook.\")],\n",
                "    \"question\": \"How old is he?\"\n",
                "})\n",
                "\n",
                "print(f\"   Input: 'How old is he?' (with context about Tim Cook)\")\n",
                "print(f\"   Output: '{result}'\")\n",
                "print(\"âœ… Query Rewriter works!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "test-generator",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Testing Generator...\n",
                        "   Question: 'Who is Tim Cook?'\n",
                        "   Answer: '\n",
                        "\n",
                        "I_DONT_KNOW'\n",
                        "âœ… Generator works!\n"
                    ]
                }
            ],
            "source": [
                "# Test Generator\n",
                "print(\"ðŸ”„ Testing Generator...\")\n",
                "\n",
                "result = components.generator.invoke({\n",
                "    \"context\": \"Tim Cook is the CEO of Apple. He was born on November 1, 1960.\",\n",
                "    \"question\": \"Who is Tim Cook?\"\n",
                "})\n",
                "\n",
                "print(f\"   Question: 'Who is Tim Cook?'\")\n",
                "print(f\"   Answer: '{result[:200]}'\")\n",
                "print(\"âœ… Generator works!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "test-graders",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Testing Retrieval Grader...\n",
                        "   Document relevant? {'binary_score': 'yes'}\n",
                        "âœ… Retrieval Grader works!\n",
                        "\n",
                        "ðŸ”„ Testing Hallucination Grader...\n",
                        "   Answer supported? {'binary_score': 'no'}\n",
                        "âœ… Hallucination Grader works!\n"
                    ]
                }
            ],
            "source": [
                "# Test Retrieval Grader\n",
                "print(\"ðŸ”„ Testing Retrieval Grader...\")\n",
                "\n",
                "result = components.retrieval_grader.invoke({\n",
                "    \"document\": \"Tim Cook is the CEO of Apple since 2011.\",\n",
                "    \"question\": \"Who is the CEO of Apple?\"\n",
                "})\n",
                "\n",
                "print(f\"   Document relevant? {result}\")\n",
                "print(\"âœ… Retrieval Grader works!\")\n",
                "\n",
                "# Test Hallucination Grader\n",
                "print(\"\\nðŸ”„ Testing Hallucination Grader...\")\n",
                "\n",
                "result = components.hallucination_grader.invoke({\n",
                "    \"documents\": \"Tim Cook was born on November 1, 1960.\",\n",
                "    \"generation\": \"Tim Cook is currently 64 years old.\"\n",
                "})\n",
                "\n",
                "print(f\"   Answer supported? {result}\")\n",
                "print(\"âœ… Hallucination Grader works!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary-section",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "**Components verified:**\n",
                "- âœ… Pydantic models (GradeDocuments, GradeHallucinations)\n",
                "- âœ… GenerationComponents dataclass\n",
                "- âœ… Query Rewriter chain\n",
                "- âœ… Generator chain\n",
                "- âœ… Retrieval Grader chain\n",
                "- âœ… Hallucination Grader chain"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
