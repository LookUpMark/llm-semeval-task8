{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MTRAGEval - Data Ingestion\n",
                "\n",
                "This notebook handles data loading and vector store creation for the SemEval 2026 Task 8 system.\n",
                "\n",
                "## Steps:\n",
                "1. Install dependencies\n",
                "2. Load mtRAG dataset\n",
                "3. Apply Parent-Child Chunking\n",
                "4. Build and persist Chroma vector store"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (run once)\n",
                "!pip install -q langchain==0.1.10 langchain-community==0.0.25 chromadb==0.4.24 sentence-transformers==2.5.1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add src to path for imports\n",
                "sys.path.insert(0, '../')\n",
                "\n",
                "# Verify GPU availability\n",
                "import torch\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "DATA_PATH = \"../data/mtrag_dataset.json\"  # Path to your mtRAG JSON file\n",
                "CHROMA_PERSIST_DIR = \"../chromadb\"\n",
                "EMBEDDING_MODEL = \"BAAI/bge-m3\"\n",
                "\n",
                "# Chunking parameters\n",
                "PARENT_CHUNK_SIZE = 1200\n",
                "PARENT_CHUNK_OVERLAP = 100\n",
                "CHILD_CHUNK_SIZE = 400\n",
                "CHILD_CHUNK_OVERLAP = 50"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load and Chunk Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import uuid\n",
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "from langchain.schema import Document\n",
                "\n",
                "def load_mtrag_data(json_path: str):\n",
                "    \"\"\"\n",
                "    Load mtRAG dataset from JSON file.\n",
                "    \n",
                "    TODO: Implement data loading logic\n",
                "    \"\"\"\n",
                "    raise NotImplementedError(\"Implement data loading from JSON\")\n",
                "\n",
                "\n",
                "def apply_parent_child_chunking(raw_docs):\n",
                "    \"\"\"\n",
                "    Apply Parent-Child chunking strategy.\n",
                "    \n",
                "    - Parent chunks: Large for context\n",
                "    - Child chunks: Small for precise retrieval\n",
                "    - Child metadata stores parent content\n",
                "    \n",
                "    TODO: Implement chunking logic\n",
                "    \"\"\"\n",
                "    raise NotImplementedError(\"Implement parent-child chunking\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute data loading and chunking\n",
                "# raw_docs = load_mtrag_data(DATA_PATH)\n",
                "# chunked_docs = apply_parent_child_chunking(raw_docs)\n",
                "# print(f\"Created {len(chunked_docs)} child chunks\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Build Vector Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.vectorstores import Chroma\n",
                "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
                "\n",
                "def build_chroma_vectorstore(docs, persist_dir, embedding_model):\n",
                "    \"\"\"\n",
                "    Build and persist Chroma vector store.\n",
                "    \n",
                "    TODO: Implement vector store creation\n",
                "    \"\"\"\n",
                "    raise NotImplementedError(\"Implement Chroma vector store creation\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build vector store\n",
                "# vectorstore = build_chroma_vectorstore(chunked_docs, CHROMA_PERSIST_DIR, EMBEDDING_MODEL)\n",
                "# print(\"Vector store built and persisted successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Verification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify vector store was created\n",
                "# test_query = \"test query\"\n",
                "# results = vectorstore.similarity_search(test_query, k=3)\n",
                "# print(f\"Found {len(results)} results for test query\")\n",
                "# for i, doc in enumerate(results):\n",
                "#     print(f\"\\nResult {i+1}:\")\n",
                "#     print(f\"  Content: {doc.page_content[:200]}...\")\n",
                "#     print(f\"  Has parent: {'parent_content' in doc.metadata}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}