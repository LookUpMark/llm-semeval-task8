{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "task-b-header",
            "metadata": {},
            "source": [
                "# SemEval 2026 Task 8 - Task B: Generation\n",
                "\n",
                "This notebook implements **Task B: Generation** for MTRAGEval.\n",
                "\n",
                "**Goal:** Given a conversation, generate an answer to the last user question.\n",
                "\n",
                "**Output Format:** JSONL with `predictions` field containing `[{\"text\": \"...\"}]`."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-section",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "\n",
                "if os.path.exists(\"src\"):\n",
                "    PROJECT_ROOT = os.getcwd()\n",
                "else:\n",
                "    PROJECT_ROOT = os.path.abspath(\"..\")\n",
                "\n",
                "if PROJECT_ROOT not in sys.path:\n",
                "    sys.path.insert(0, PROJECT_ROOT)\n",
                "\n",
                "from src.graph import initialize_graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "TEAM_NAME = \"Gbgers\"\n",
                "DOMAINS = [\"govt\", \"clapnq\", \"fiqa\", \"cloud\"]\n",
                "\n",
                "# TEST MODE: Set to True for quick verification\n",
                "TEST_MODE = True\n",
                "TEST_QUERY_LIMIT = 5  # Queries per domain in test mode\n",
                "\n",
                "CONVERSATIONS_FILE = os.path.join(PROJECT_ROOT, \"dataset/human/conversations/conversations.json\")\n",
                "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"data/submissions\")\n",
                "OUTPUT_FILE = os.path.join(OUTPUT_DIR, f\"submission_TaskB_{TEAM_NAME}.jsonl\")\n",
                "\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "print(f\"Processing domains: {DOMAINS}\")\n",
                "if TEST_MODE:\n",
                "    print(f\"‚ö†Ô∏è TEST MODE: Processing only {TEST_QUERY_LIMIT} queries per domain.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "helper-section",
            "metadata": {},
            "source": [
                "## 2. Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "helpers",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_last_user_question(messages):\n",
                "    \"\"\"Extract the last user message from conversation.\"\"\"\n",
                "    for msg in reversed(messages):\n",
                "        if msg.get(\"speaker\") == \"user\":\n",
                "            return msg.get(\"text\", \"\")\n",
                "    return \"\"\n",
                "\n",
                "def format_input_for_output(messages):\n",
                "    \"\"\"Format messages for submission output.\"\"\"\n",
                "    return [{\"speaker\": m[\"speaker\"], \"text\": m[\"text\"]} for m in messages]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "init-section",
            "metadata": {},
            "source": [
                "## 3. Initialize Graph and Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "init-graph",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the RAG graph\n",
                "print(\"üîß Initializing RAG graph...\")\n",
                "app = initialize_graph()\n",
                "print(\"‚úÖ Graph ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load-data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load conversations\n",
                "print(\"üìÇ Loading conversations...\")\n",
                "with open(CONVERSATIONS_FILE, 'r') as f:\n",
                "    all_conversations = json.load(f)\n",
                "print(f\"Total conversations: {len(all_conversations)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "process-section",
            "metadata": {},
            "source": [
                "## 4. Run Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "process-all",
            "metadata": {},
            "outputs": [],
            "source": [
                "all_results = []\n",
                "\n",
                "for domain in DOMAINS:\n",
                "    print(f\"\\n{'='*40}\\nüåç DOMAIN: {domain.upper()}\\n{'='*40}\")\n",
                "    \n",
                "    # Filter by domain (substring match)\n",
                "    domain_convs = [c for c in all_conversations if domain.lower() in c.get(\"domain\", \"\").lower()]\n",
                "    print(f\"Found {len(domain_convs)} conversations\")\n",
                "    \n",
                "    if not domain_convs:\n",
                "        continue\n",
                "    \n",
                "    if TEST_MODE:\n",
                "        print(f\"‚úÇÔ∏è TEST MODE: Processing {TEST_QUERY_LIMIT} queries\")\n",
                "        domain_convs = domain_convs[:TEST_QUERY_LIMIT]\n",
                "    \n",
                "    print(f\"üöÄ Running generation...\")\n",
                "    for conv in tqdm(domain_convs):\n",
                "        messages = conv.get(\"messages\", [])\n",
                "        question = extract_last_user_question(messages)\n",
                "        \n",
                "        if not question:\n",
                "            continue\n",
                "        \n",
                "        try:\n",
                "            # Invoke graph\n",
                "            response = app.invoke({\"question\": question})\n",
                "            gen_text = response.get(\"generation\", \"No Answer\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error: {e}\")\n",
                "            gen_text = \"Error\"\n",
                "        \n",
                "        # Format output\n",
                "        all_results.append({\n",
                "            \"conversation_id\": conv.get(\"author\"),  # Using author as ID if no explicit ID\n",
                "            \"Collection\": f\"mt-rag-{domain}\",\n",
                "            \"input\": format_input_for_output(messages),\n",
                "            \"predictions\": [{\"text\": gen_text}]\n",
                "        })\n",
                "\n",
                "print(f\"\\n‚úÖ Generated {len(all_results)} answers.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "save-section",
            "metadata": {},
            "source": [
                "## 5. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"üíæ Saving {len(all_results)} results to {OUTPUT_FILE}...\")\n",
                "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
                "    for item in all_results:\n",
                "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
                "print(\"‚úÖ Done!\")\n",
                "\n",
                "# Validation\n",
                "if all_results:\n",
                "    sample = all_results[0]\n",
                "    if \"predictions\" in sample and isinstance(sample[\"predictions\"], list):\n",
                "        print(\"\\033[92mVALIDATION PASS: Structure correct.\\033[0m\")\n",
                "    else:\n",
                "        print(\"\\033[91mVALIDATION FAIL: 'predictions' format error.\\033[0m\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}