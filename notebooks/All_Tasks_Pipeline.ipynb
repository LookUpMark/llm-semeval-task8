{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "title",
            "metadata": {},
            "source": [
                "# SemEval 2026 Task 8: Multi-Turn RAG Evaluation\n",
                "\n",
                "## Complete Pipeline for All Tasks (Graph-Enhanced)\n",
                "\n",
                "This pipeline generates submissions for Tasks A, B, and C.\n",
                "\n",
                "- **Task A (Retrieval)**: Uses BGE-M3 + Cross-Encoder Reranking.\n",
                "- **Task B (Generation)**: Uses Direct LLM (Llama 3.1) with constraints.\n",
                "- **Task C (RAG)**: Uses **Self-CRAG Graph** with Hallucination Check & Retries.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "kaggle_env",
            "metadata": {},
            "outputs": [],
            "source": [
                "# KAGGLE SETUP (uncomment on Kaggle)\n",
                "# import os\n",
                "# if not os.path.exists(\"llm-semeval-task8\"):\n",
                "#     !git clone https://github.com/LookUpMark/llm-semeval-task8.git\n",
                "# %cd llm-semeval-task8\n",
                "# !git checkout dev\n",
                "# !pip install -q langchain langchain-community langchain-huggingface langchain-qdrant qdrant-client sentence-transformers bitsandbytes accelerate transformers tqdm langgraph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, json, zipfile\n",
                "from tqdm import tqdm\n",
                "\n",
                "if os.path.exists(\"src\"): PROJECT_ROOT = os.getcwd()\n",
                "elif os.path.exists(\"llm-semeval-task8\"): PROJECT_ROOT = \"llm-semeval-task8\"\n",
                "else: PROJECT_ROOT = os.path.abspath(\"..\")\n",
                "if PROJECT_ROOT not in sys.path: sys.path.insert(0, PROJECT_ROOT)\n",
                "\n",
                "# Ingestion & Retrieval\n",
                "from src.ingestion import load_and_chunk_data, build_vector_store\n",
                "from src.retrieval import get_retriever, get_qdrant_client\n",
                "\n",
                "# Task B (Simple Gen) & Helper\n",
                "from src.generation import create_generation_components\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "# Task C (Advanced Graph)\n",
                "from src.graph import initialize_graph\n",
                "\n",
                "print(f\"Project: {PROJECT_ROOT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CONFIGURATION\n",
                "# ============================================================\n",
                "TEAM_NAME = \"Gbgers\"\n",
                "DOMAINS = [\"govt\", \"clapnq\", \"fiqa\", \"cloud\"]\n",
                "COLLECTION_NAME = \"mtrag_unified\"\n",
                "\n",
                "# --- IMPORTANT: Adjust these for your hardware ---\n",
                "# TEST_MODE = True uses small subsets (~1k docs)\n",
                "# TEST_MODE = False uses MAX_DOCS_PER_DOMAIN (~25k docs) for submission\n",
                "TEST_MODE = False\n",
                "\n",
                "TEST_CHUNK_LIMIT = 1000      # Chunks per domain for indexing\n",
                "TEST_QUERY_LIMIT = 5         # Conversations per domain\n",
                "\n",
                "# For FULL mode (~2.5h run)\n",
                "MAX_DOCS_PER_DOMAIN = 25000\n",
                "\n",
                "# Paths\n",
                "CORPUS_DIR = os.path.join(PROJECT_ROOT, \"dataset/corpora/passage_level\")\n",
                "CONV_FILE = os.path.join(PROJECT_ROOT, \"dataset/human/conversations/conversations.json\")\n",
                "QDRANT_PATH = os.path.join(PROJECT_ROOT, \"qdrant_db\")\n",
                "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"data/submissions\")\n",
                "\n",
                "FILE_A = os.path.join(OUTPUT_DIR, f\"submission_TaskA_{TEAM_NAME}.jsonl\")\n",
                "FILE_B = os.path.join(OUTPUT_DIR, f\"submission_TaskB_{TEAM_NAME}.jsonl\")\n",
                "FILE_C = os.path.join(OUTPUT_DIR, f\"submission_TaskC_{TEAM_NAME}.jsonl\")\n",
                "\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "os.makedirs(QDRANT_PATH, exist_ok=True)\n",
                "\n",
                "print(f\"Mode: {'TEST' if TEST_MODE else 'FULL'}\")\n",
                "if not TEST_MODE:\n",
                "    print(f\"Max docs/domain: {MAX_DOCS_PER_DOMAIN}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "helpers",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_last_query(msgs): return next((m[\"text\"] for m in reversed(msgs) if m.get(\"speaker\")==\"user\"), \"\")\n",
                "\n",
                "def get_corpus(domain):\n",
                "    p = os.path.join(CORPUS_DIR, f\"{domain}.jsonl\")\n",
                "    z = p + \".zip\"\n",
                "    if not os.path.exists(p) and os.path.exists(z):\n",
                "        with zipfile.ZipFile(z) as zf: zf.extractall(CORPUS_DIR)\n",
                "    return p if os.path.exists(p) else None\n",
                "\n",
                "def save_jsonl(data, path):\n",
                "    with open(path, 'w') as f:\n",
                "        for d in data: f.write(json.dumps(d, ensure_ascii=False)+'\\n')\n",
                "    print(f\"Saved {len(data)} -> {path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "build_index",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build Index\n",
                "need_build = True\n",
                "try:\n",
                "    client = get_qdrant_client(QDRANT_PATH)\n",
                "    if client.collection_exists(COLLECTION_NAME):\n",
                "        print(f\"Collection exists: {client.get_collection(COLLECTION_NAME).points_count} vectors\")\n",
                "        need_build = False\n",
                "except: pass\n",
                "\n",
                "if need_build:\n",
                "    print(f\"Building '{COLLECTION_NAME}'...\")\n",
                "    all_docs = []\n",
                "    limit = TEST_CHUNK_LIMIT if TEST_MODE else MAX_DOCS_PER_DOMAIN\n",
                "    \n",
                "    for domain in DOMAINS:\n",
                "        path = get_corpus(domain)\n",
                "        if not path: continue\n",
                "        print(f\"Loading {domain}...\")\n",
                "        docs = load_and_chunk_data(path)\n",
                "        for d in docs: d.metadata[\"domain\"] = domain\n",
                "        \n",
                "        # Apply limit\n",
                "        if len(docs) > limit:\n",
                "            print(f\"  Limiting: {len(docs)} -> {limit}\")\n",
                "            docs = docs[:limit]\n",
                "        \n",
                "        all_docs.extend(docs)\n",
                "        print(f\"  Added {len(docs)} chunks\")\n",
                "    \n",
                "    print(f\"Total: {len(all_docs)} chunks\")\n",
                "    build_vector_store(all_docs, persist_dir=QDRANT_PATH, collection_name=COLLECTION_NAME)\n",
                "    print(\"Done.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "init_components",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Components\n",
                "print(\"Loading Retriever...\")\n",
                "retriever = get_retriever(qdrant_path=QDRANT_PATH, collection_name=COLLECTION_NAME)\n",
                "\n",
                "print(\"Loading LLM for Task B...\")\n",
                "gen_components = create_generation_components()\n",
                "\n",
                "print(\"Initializing Advanced Graph for Task C...\")\n",
                "graph_app = initialize_graph()\n",
                "\n",
                "# Task B chain (no context)\n",
                "task_b_prompt = PromptTemplate(\n",
                "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
                "You are an expert assistant. Answer based on your knowledge. Be concise.<|eot_id|>\n",
                "<|start_header_id|>user<|end_header_id|>\n",
                "{question}<|eot_id|>\n",
                "<|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
                "    input_variables=[\"question\"]\n",
                ")\n",
                "task_b_chain = task_b_prompt | gen_components.llm | StrOutputParser()\n",
                "print(\"All Systems Ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "execute",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute Pipeline\n",
                "with open(CONV_FILE) as f: conversations = json.load(f)\n",
                "results_A, results_B, results_C = [], [], []\n",
                "\n",
                "for domain in DOMAINS:\n",
                "    print(f\"\\n=== {domain.upper()} ===\")\n",
                "    convs = [c for c in conversations if domain in c.get(\"domain\", \"\").lower()]\n",
                "    if TEST_MODE: convs = convs[:TEST_QUERY_LIMIT]\n",
                "    print(f\"Processing {len(convs)} conversations\")\n",
                "    \n",
                "    for conv in tqdm(convs, desc=domain):\n",
                "        msgs = conv.get(\"messages\", [])\n",
                "        q = extract_last_query(msgs)\n",
                "        if not q: continue\n",
                "        \n",
                "        # --- Task A: Retrieve ---\n",
                "        docs = retriever.invoke(q)\n",
                "        contexts = []\n",
                "        for i, d in enumerate(docs):\n",
                "            txt = d.metadata.get(\"parent_text\") or d.page_content\n",
                "            contexts.append({\"document_id\": str(d.metadata.get(\"doc_id\", f\"{domain}_{i}\")), \"score\": 0.0, \"text\": txt})\n",
                "        \n",
                "        # --- Task B: Generate (simple) ---\n",
                "        try: ans_b = task_b_chain.invoke({\"question\": q})\n",
                "        except Exception as e: ans_b = str(e)\n",
                "        \n",
                "        # --- Task C: RAG Generate (Advanced Graph) ---\n",
                "        try:\n",
                "            # Uses Self-CRAG with Retries\n",
                "            response = graph_app.invoke({\"question\": q, \"domain\": domain})\n",
                "            ans_c = response.get(\"generation\", \"I_DONT_KNOW\")\n",
                "        except Exception as e:\n",
                "            ans_c = str(e)\n",
                "        \n",
                "        base = {\"conversation_id\": conv.get(\"author\"), \"task_id\": f\"{conv.get('author')}::1\", \"Collection\": f\"mt-rag-{domain}\", \"input\": msgs}\n",
                "        results_A.append({**base, \"contexts\": contexts})\n",
                "        results_B.append({**base, \"predictions\": [{\"text\": ans_b}]})\n",
                "        results_C.append({**base, \"contexts\": contexts, \"predictions\": [{\"text\": ans_c}]})\n",
                "\n",
                "print(f\"\\nTotal: {len(results_A)} results\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "save",
            "metadata": {},
            "outputs": [],
            "source": [
                "save_jsonl(results_A, FILE_A)\n",
                "save_jsonl(results_B, FILE_B)\n",
                "save_jsonl(results_C, FILE_C)\n",
                "print(\"Done!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}